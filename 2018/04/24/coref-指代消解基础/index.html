
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  
    <title>【Coref】指代消解基础 | Blog of YQ</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Yuanqing Zhu">
    

    
    <meta name="description" content="组会相关内容分享">
<meta name="keywords" content="Coreference Resolution,NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="【Coref】指代消解基础">
<meta property="og:url" content="http://yoursite.com/2018/04/24/coref-指代消解基础/index.html">
<meta property="og:site_name" content="Blog of YQ">
<meta property="og:description" content="组会相关内容分享">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/mention_and_entity.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/tree.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/clipboard.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_1.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_2.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_4.png">
<meta property="og:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_5.png">
<meta property="og:updated_time" content="2023-08-25T06:11:55.220Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【Coref】指代消解基础">
<meta name="twitter:description" content="组会相关内容分享">
<meta name="twitter:image" content="http://yoursite.com/2018/04/24/coref-指代消解基础/指代消解基础/mention_and_entity.png">

    
    <link rel="alternative" href="atom.xml" title="Blog of YQ" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/icon.ico">
    
    
    <link rel="apple-touch-icon" href="//img/IMG_8752.JPG">
    <link rel="apple-touch-icon-precomposed" href="//img/IMG_8752.JPG">
    
    <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
</html>
  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Blog of YQ">Blog of YQ</a></h1>
				<h2 class="blog-motto">this is subtitle :)</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索">
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</ul></nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope="" itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/04/24/coref-指代消解基础/" title="【Coref】指代消解基础" itemprop="url">【Coref】指代消解基础</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yuanqing Zhu" target="_blank" itemprop="author">Yuanqing Zhu</a>
		
  </p><p class="article-time">
    <time datetime="2018-04-23T16:00:00.000Z" itemprop="datePublished"> 发表于 2018-04-24</time>
    
  </p>
</header>
	<div class="article-content">
		
		<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#gainian">一些概念</a><ol>
<li><a href="#01">指代概念</a></li>
<li><a href="#mention">表述与实体</a></li>
<li><a href="#mission">消解任务</a></li>
</ol>
</li>
<li><a href="#function">各类方法</a><ol>
<li><a href="#md">表述提取</a><ul>
<li><a href="#parse">利用句法树</a></li>
<li><a href="#nn">利用神经网络</a></li>
</ul>
</li>
<li><a href="#cr">消解</a><ul>
<li><a href="#language">语言学</a></li>
<li><a href="#ml">机器学习</a></li>
</ul>
</li>
</ol>
</li>
<li><a href="#multisieve">CR——Multi sieve</a><ol>
<li><a href="#idea">想法</a></li>
<li><a href="#ms-md">表述提取</a></li>
<li><a href="#ms-cr/">消解</a></li>
</ol>
</li>
<li><a href="#end2end">CR——End2End</a><ol>
<li><a href="#e2e-mission">目标任务</a></li>
<li><a href="#e2e-function">论文方法</a></li>
<li><a href="#answer">讨论</a><ul>
<li><a href="#strength">优点</a></li>
<li><a href="#weakness">缺点</a></li>
<li><a href="#improved">改进</a></li>
</ul>
</li>
<li><a href="#experiment">实验</a></li>
</ol>
</li>
<li><a href="#url">可能有用的网址</a></li>
<li><a href="#recommend">私货</a></li>
</ol>
<hr>
<h3 id="一、-一些概念"><a href="#一、-一些概念" class="headerlink" title="一、 一些概念 "></a><span id="gainian">一、 一些概念 </span></h3><h4 id="1-指代概念"><a href="#1-指代概念" class="headerlink" title="1. 指代概念"></a><span id="01">1. 指代概念</span></h4><p>指代（coreference）为语言学中为了避免已经出现的字词重复出现在文章的句子上，导致语句结构过于赘述和语意不够清晰，所以使用代词（pronouns）或是普通名词（common nouns）来代替已经出现过的字词。</p>
<p>主要分为两类：<strong>回指</strong>和<strong>共指</strong></p>
<ul>
<li>回指：指句子中出现的短语存在着密切的语义关联性，指代同一事物。这种关系依赖上下文语义。其中被指向的语言单位被称为先行语</li>
<li><p>共指：指句子中出现的短语指向真实世界的同一参照体，这种指代脱离上下文仍然成立。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">例如：</span><br><span class="line">回指：“小明很帅，同学们都很喜欢他。”</span><br><span class="line">共指：“特朗普就任总统以来第一次访问中国，他也将成为历史上第8位在任时访华的美国总统。”</span><br><span class="line"></span><br><span class="line">句子一中，&apos;他&apos;指代&apos;小明&apos;，&apos;小明&apos;是&apos;他&apos;的先行语。</span><br><span class="line">句子二中，&apos;特朗普&apos;和&apos;美国总统&apos;均指代在美国白宫坐着的那个人类。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>

</p><h4 id="2-表述与实体"><a href="#2-表述与实体" class="headerlink" title="2. 表述与实体"></a><span id="mention">2. 表述与实体</span></h4><p>实体（Entity）是存在于客观世界的某种事物，是一种切实存在的概念。文本中会出现很多的名词短语以及代词，这些句子成分被称作表述（Mention），是一个事物在文本中的一种体现。</p>
<blockquote>
<p>In coreference resolution, an entity is an object or set of objects in the world, while a mention is the textual reference to an entity (Doddington et al., 2004). </p>
</blockquote>
<p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/mention_and_entity.png" alt="image"></p>
<h4 id="3-任务描述"><a href="#3-任务描述" class="headerlink" title="3. 任务描述"></a><span id="mission">3. 任务描述</span></h4><p>指代消解定义：为文中的表述确定其在真实世界中所指向实体的过程。</p>
<blockquote>
<p>Coreference resolution, the task of identifying which mentions in a text refer to the same real world entity, is fundamentally a clustering problem. </p>
</blockquote>
<p>研究步骤：</p>
<ol>
<li>Mention detection/表述提取——对于一段文本，抽取其中的表述。</li>
<li>Coreference Resolution/指代消解——对上一步得到的表述进行分析，确定它们之间是否存在指代关系。</li>
</ol>
<h3 id="二-各类方法"><a href="#二-各类方法" class="headerlink" title="二. 各类方法"></a><span id="function">二. 各类方法</span></h3><h4 id="1-表述提取"><a href="#1-表述提取" class="headerlink" title="1. 表述提取"></a><span id="md">1. 表述提取</span></h4><ul>
<li><p><span id="parse">利用句法分析树</span></p>
<p>  对输入的文本进行分词、词性标注等工作，以句子为单位构建句法树。对产生的句法树进行分析，获取其中的各个子树。选取所有的根节点为名词短语（或代词）的子树，抽取其中的词语组合成候选表述</p>
<p>  输入：</p>
<blockquote>
<p>(TOP(IP(NP(QP0) (NP1) (NP2)) (VP(PP3 (IP(VP(ADVP4) (VP5 (NP6))))) (VP7 (NP8))) 9))</p>
</blockquote>
<p>  输出：</p>
<blockquote>
<p>0、1、01、5、45、8</p>
</blockquote>
<p>  <img src="/2018/04/24/coref-指代消解基础/指代消解基础/tree.png" alt="image"></p>
</li>
<li><p><span id="nn">利用神经网络</span></p>
<p>  对输入的文本进行分词工作，将每个词语作为一个基本单位进行保存。通过词嵌入（word embedding）构建包含更多词信息的词向量，然后输入双向LSTM网络获取对应的候选表述。（详见后文）</p>
</li>
</ul>
<h4 id="2-消解"><a href="#2-消解" class="headerlink" title="2. 消解"></a><span id="cr">2. 消解</span></h4><ul>
<li><p><span id="language">语言学方法</span></p>
<ul>
<li>Hobbs算法是最早的代词消解方法之一，主要依赖于句法解析树进行分析。</li>
<li>Grosz提出并发展起来的中心理论主要针对篇章结构中的焦点转移以及话语一致性等问题，常用于代词消解研究。</li>
<li>Raghunathan(2010)针对英文数据集构建了一种多轮迭代(MultiSieves)处理的方法，该方法根据准确率由高到低构建了多个筛子（sieve）用来为文本中的表述选取先行语。<a href="http://www.aclweb.org/anthology/D10-1048" target="_blank" rel="noopener">Multi-sieves论文：http://www.aclweb.org/anthology/D10-1048</a></li>
</ul>
</li>
<li><p><span id="ml">机器学习方法</span></p>
<ul>
<li>常见的四类框架包括实体-表述模型、表述对模型、表述排序模型和实体排序模型。</li>
<li>其中表述对模型是最常见的模型之一，该模型将消解问题看作是表述对之间的二分类问题，判断系统当前处理的两个表述之间是否存在着共指关系。</li>
<li>人们在此基础上进行修改，提出了实体-表述模型和表述排序模型。</li>
<li>为了组合实体-表述模型和表述排序模型的优势，提出了实体排序模型。</li>
<li>关于表述排序模型(Mention-Ranking)可以参考：<a href="https://nlp.stanford.edu/pubs/clark2016improving.pdf" target="_blank" rel="noopener">Improving Coreference Resolution by Learning Entity-Level Distributed</a></li>
</ul>
</li>
</ul>
<h3 id="三-CR——MultiSieves"><a href="#三-CR——MultiSieves" class="headerlink" title="三. CR——MultiSieves"></a><span id="multisieve">三. CR——MultiSieves</span></h3><h4 id="0-想法"><a href="#0-想法" class="headerlink" title="0. 想法"></a>0. <span id="idea">想法</span></h4><p>通过某种方法从文本中获取表述，对这些表述进行多轮(sieve)处理，每一轮针对文本不同的特性，处理自己能识别出存在指代关系的表述，然后再将处理的结果传递给下一轮，通过多轮处理后，输出最终的消解结果。这种方案的优势在于构建了一个消解平台，后人可以在基础上很方便的增删改。</p>
<p>参考论文：</p>
<ul>
<li>Raghunathan K, Lee H, Rangarajan S, et al. A Multi-Pass Sieve for Coreference Resolution.[C]// Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 October 2010, Mit Stata Center, Massachusetts, Usa, A Meeting of Sigdat, A Special Interest Group of the ACL. DBLP, 2011:492-501.</li>
<li>Lee H, Peirsman Y, Chang A, et al. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task[C]// Fifteenth Conference on Computational Natural Language Learning: Shared Task. 2012:28-34.</li>
<li>Chen C, Ng V. Combining the best of two worlds: a hybrid approach to multilingual coreference resolution[C]// Joint Conference on EMNLP and CoNLL - Shared Task. Association for Computational Linguistics, 2012:56-63.</li>
<li>Chen C, Ng V. Chinese Noun Phrase Coreference Resolution: Insights into the State of the Art[C]// COLING 2012: Posters. 2013:185-194.</li>
</ul>
<h4 id="1-Mention-Detection"><a href="#1-Mention-Detection" class="headerlink" title="1. Mention Detection"></a>1. <span id="ms-md">Mention Detection</span></h4><p>使用了Stanford的工具包对文本进行预处理</p>
<ul>
<li><a href="https://github.com/Lynten/stanford-corenlp" target="_blank" rel="noopener">https://github.com/Lynten/stanford-corenlp</a></li>
<li><a href="https://stanfordnlp.github.io/CoreNLP/#download" target="_blank" rel="noopener">https://stanfordnlp.github.io/CoreNLP/#download</a></li>
<li><a href="https://stanfordnlp.github.io/CoreNLP/history.html" target="_blank" rel="noopener">https://stanfordnlp.github.io/CoreNLP/history.html</a></li>
</ul>
<p><strong>使用示例：</strong></p>
<p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/clipboard.png" alt="image"></p>
<p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_1.png" alt="image"></p>
<p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_2.png" alt="image"></p>
<p>输入</p>
<blockquote>
<p>“小明很帅，同学们都很喜欢他”</p>
</blockquote>
<p>得到：</p>
<blockquote>
<p>明 小明 很帅 小明很帅 同学们 他</p>
</blockquote>
<h4 id="2-Coreference-Resolution"><a href="#2-Coreference-Resolution" class="headerlink" title="2. Coreference Resolution"></a>2. <span id="ms-cr">Coreference Resolution</span></h4><ul>
<li><p>主要想法：<br>通过某种方法从文本中获取表述，对这些表述进行多轮(sieve)处理，每一轮针对文本不同的特性，处理自己能识别出存在指代关系的表述，然后再将处理的结果传递给下一轮，通过多轮处理后，输出最终的消解结果。这种方案的优势在于构建了一个消解平台，后人可以在基础上很方便的增删改。</p>
</li>
<li><p>参考论文：</p>
<ul>
<li>Raghunathan K, Lee H, Rangarajan S, et al. A Multi-Pass Sieve for Coreference Resolution.[C]// Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 October 2010, Mit Stata Center, Massachusetts, Usa, A Meeting of Sigdat, A Special Interest Group of the ACL. DBLP, 2011:492-501.</li>
<li>Lee H, Peirsman Y, Chang A, et al. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task[C]// Fifteenth Conference on Computational Natural Language Learning: Shared Task. 2012:28-34.</li>
<li>Chen C, Ng V. Combining the best of two worlds: a hybrid approach to multilingual coreference resolution[C]// Joint Conference on EMNLP and CoNLL - Shared Task. Association for Computational Linguistics, 2012:56-63.</li>
<li>Chen C, Ng V. Chinese Noun Phrase Coreference Resolution: Insights into the State of the Art[C]// COLING 2012: Posters. 2013:185-194.</li>
</ul>
</li>
<li>常用的sieves  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. Mention Detection Sieve </span><br><span class="line">2. Discourse Processing Sieve</span><br><span class="line">3. Exact String Match Sieve </span><br><span class="line">4. Relaxed String Match Sieve </span><br><span class="line">5. Precise Constructs Sieve </span><br><span class="line">6-8. Strict Head Matching Sieves A-C</span><br><span class="line">9. Proper HeadWord Match Sieve </span><br><span class="line">10. Alias Sieve </span><br><span class="line">11. Relaxed Head Matching Sieve </span><br><span class="line">12. Lexical Chain Sieve </span><br><span class="line">13. Pronouns Sieve</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-CR——End2End"><a href="#4-CR——End2End" class="headerlink" title="4. CR——End2End"></a>4. <span id="end2end">CR——End2End</span></h3><p>论文名城：End-to-end Neural Coreference Resolution</p>
<h4 id="1-目标任务"><a href="#1-目标任务" class="headerlink" title="1. 目标任务"></a>1. <span id="e2e-mission">目标任务</span></h4><p>对于指代消解的任务定义为：<br>给定一段文本，找到其中名词/代词，判断这些词语是否存在着指代关系。</p>
<p>因此给定一个包含T个词语的文档D，通过某种方法从中得到N个span(即将这些span作为潜在的表述)。==论文目标是对于每个span 𝑖确定一个先行语y_𝑖==</p>
<p>𝑦_𝑖可能的取值集合: 𝒴(𝑖)={𝜖,1,…,𝑖−1}<br>𝜖：表示当前span没有先行语</p>
<p>其中span是由几个单词组成的一个单元，可以理解为一个短语/词组</p>
<h4 id="2-论文方法"><a href="#2-论文方法" class="headerlink" title="2. 论文方法"></a>2. <span id="e2e-function">论文方法</span></h4><p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_4.png" alt="image"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>顺序</th>
<th>任务</th>
<th>得到</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>对于每个单词，使用300维GloVe embedding和50维Turian embedding构成向量，进行正则化为单元向量。对于每个字符，通过一个卷积网络得到一个8维向量进行表示</td>
<td>word &amp; character embedding 𝒙</td>
</tr>
<tr>
<td>2</td>
<td>将上一步中的向量表示输入双向LSTM网络，对文本中每个词进行编码和计算，得到span 𝑖的边界的表示向量x<em>(𝑆𝑇𝐴𝑅𝑇(𝑖))^∗和x</em>(𝐸𝑁𝐷(𝑖))^∗</td>
<td>𝒙<em>(𝑆𝑇𝐴𝑅𝑇(𝑖))^∗和𝒙</em>(𝐸𝑁𝐷(𝑖))^∗</td>
</tr>
<tr>
<td>3</td>
<td>利用attention机制求取每个候选span的中心词𝑥 ̂_𝑖</td>
<td>span 𝑖 的中心词𝒙 ̂_𝒊</td>
</tr>
<tr>
<td>4</td>
<td>构建对于span的向量表示：𝑔<em>𝑖=[x</em>𝑆𝑇𝐴𝑅𝑇(𝑖)^ ∗,x<em>𝐸𝑁𝐷(𝑖)^∗,𝑥 ̂</em>𝑖,∅(𝑖)]</td>
<td>span的向量表示𝑔_𝑖</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2018/04/24/coref-指代消解基础/指代消解基础/clipboard_5.png" alt="image"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>顺序</th>
<th>任务</th>
<th>得到</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>对于每个span 𝑖，计算𝑠<em>𝑚，其中s</em>𝑚=𝜔<em>𝑚∙[𝐹𝐹𝑁𝑁]</em>𝑚 (𝑔<em>𝑖) FFNN为一个非线性映射的前馈神经网络。s</em>𝑚的意义在于对span空间进行剪枝，删去过多的表述。</td>
<td>𝑠_𝑚</td>
</tr>
<tr>
<td>2</td>
<td>对于span 𝑖，𝑗，计算𝑠<em>a (𝑖,𝑗)，其中𝑠_a (𝑖,𝑗)=𝜔</em>𝑎∙[𝐹𝐹𝑁𝑁]<em>𝑎 ([𝑔</em>𝑖,𝑔<em>𝑗,𝑔</em>𝑖°𝑔<em>𝑗,∅(𝑖,𝑗)])，s</em>𝑎 的意义即span 𝑗是span 𝑖的先行词的score</td>
<td>𝑠_a (𝑖,𝑗)</td>
</tr>
<tr>
<td>3</td>
<td>计算S(𝑖,𝑗)</td>
<td>S(𝑖,𝑗)</td>
</tr>
</tbody>
</table>
</div>
<h4 id="小结—计算流程"><a href="#小结—计算流程" class="headerlink" title="小结—计算流程"></a>小结—计算流程</h4><ol>
<li>word representation 𝒙</li>
<li>LSTM 𝑥^∗</li>
<li>head 𝑥 ̂_𝑖</li>
<li>span representation 𝑔_𝑖</li>
<li>Mention score s_𝑚(pruning)</li>
<li>Antecedent score 𝑠_a (𝑖,𝑗)</li>
<li>Coreference score s(𝑖,𝑗)</li>
</ol>
<h4 id="3-讨论"><a href="#3-讨论" class="headerlink" title="3. 讨论"></a>3. <span id="answer">讨论</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 以前方法的缺陷</span><br><span class="line">    在之前的各类方法中，大部分是依赖语法分析树和手工构建的各种特征。</span><br><span class="line">    存在以下问题：</span><br><span class="line">        1. 句法分析器的错误可能导致一连串的错误</span><br><span class="line">        2. 许多手工构建的规则对于新的语言或任务不具有普适性</span><br><span class="line">- 本论文不依赖于句法分析器，不依赖于手工构建的各类规则</span><br></pre></td></tr></table></figure>
<p><span id="strength"><strong>优点</strong></span></p>
<ol>
<li>本文的模型可以有效提取较长和复杂的词语作为潜在的表述</li>
<li>Attention机制在确定指代关系的工作中有重要作用（通过查找中心词）</li>
<li>由双向LSTM提供的上下文信息在确定指代关系中也起到了重要作用</li>
</ol>
<p><span id="weakness"><strong>缺点</strong></span></p>
<ol>
<li>论文可以利用embeedding计算词语之间的相似度，这是基于传统的特征的系统所不能解决的。但是有时在embedding相似的情况下，但是语义并不相近。</li>
<li>本模型缺少关于现实世界的先验知识</li>
</ol>
<p><span id="improved"><strong>改进</strong></span></p>
<ul>
<li>将模型与外部世界的知识相结合</li>
<li>用更大量的训练数据克服这些缺陷</li>
</ul>
<h3 id="5-可能有用的Urls"><a href="#5-可能有用的Urls" class="headerlink" title="5. 可能有用的Urls"></a>5. <span id="urls">可能有用的Urls</span></h3><div class="table-container">
<table>
<thead>
<tr>
<th>网址</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/Lynten/stanford-coren" target="_blank" rel="noopener">https://github.com/Lynten/stanford-coren</a></td>
<td>Stanfordcorenlp项目地址</td>
</tr>
<tr>
<td><a href="https://stanfordnlp.github.io/CoreNLP/#download" target="_blank" rel="noopener">https://stanfordnlp.github.io/CoreNLP/#download</a></td>
<td>最新版CoreNLP模型下载地址</td>
</tr>
<tr>
<td><a href="https://stanfordnlp.github.io/CoreNLP/history.html" target="_blank" rel="noopener">https://stanfordnlp.github.io/CoreNLP/history.html</a></td>
<td>CoreNLP模型历史版本下载地址</td>
</tr>
<tr>
<td><a href="http://allennlp.org/" target="_blank" rel="noopener">http://allennlp.org/</a></td>
<td>一个基于PyTorch的新的开源NLP研究库。 </td>
</tr>
<tr>
<td><a href="https://github.com/kentonl/e2e-coref" target="_blank" rel="noopener">https://github.com/kentonl/e2e-coref</a></td>
<td>End2End CR论文的项目地址</td>
</tr>
</tbody>
</table>
</div>
<h4 id="6-私货"><a href="#6-私货" class="headerlink" title="6. 私货"></a>6. <span id="recommend">私货<span></span></span></h4><ul>
<li><a href="https://weibo.com/52nlp" target="_blank" rel="noopener">https://weibo.com/52nlp</a></li>
<li><a href="https://weibo.com/u/1657470871" target="_blank" rel="noopener">https://weibo.com/u/1657470871</a></li>
<li><a href="https://weibo.com/paperweekly" target="_blank" rel="noopener">https://weibo.com/paperweekly</a></li>
<li><a href="https://weibo.com/fly51fly" target="_blank" rel="noopener">https://weibo.com/fly51fly</a></li>
<li><a href="https://weibo.com/jietangthu" target="_blank" rel="noopener">https://weibo.com/jietangthu</a></li>
<li><a href="https://weibo.com/u/1970879995" target="_blank" rel="noopener">https://weibo.com/u/1970879995</a></li>
<li><a href="https://weibo.com/zibuyu9" target="_blank" rel="noopener">https://weibo.com/zibuyu9</a></li>
<li><a href="https://weibo.com/clnlp" target="_blank" rel="noopener">https://weibo.com/clnlp</a></li>
<li><a href="https://weibo.com/nlpjob" target="_blank" rel="noopener">https://weibo.com/nlpjob</a></li>
<li><a href="https://weibo.com/arnetminer" target="_blank" rel="noopener">https://weibo.com/arnetminer</a></li>
<li><a href="http://blog.knownsec.com/Knownsec_RD_Checklist/index.html" target="_blank" rel="noopener">http://blog.knownsec.com/Knownsec_RD_Checklist/index.html</a></li>
<li><a href="https://github.com/dongxiexidian/Chinese" target="_blank" rel="noopener">https://github.com/dongxiexidian/Chinese</a></li>
<li><a href="https://github.com/justjavac/free-programming-books-zh_CN" target="_blank" rel="noopener">https://github.com/justjavac/free-programming-books-zh_CN</a></li>
<li><a href="https://www.jianshu.com/u/ZQtGe6" target="_blank" rel="noopener">https://www.jianshu.com/u/ZQtGe6</a></li>
</ul>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Coreference-Resolution/">Coreference Resolution</a><a href="/tags/NLP/">NLP</a>
  </div>

</div>



</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev">
 <a href="/2018/07/14/coref-paper-笔记-A Hybrid Approach to Multilingual Coreference Resolution/" title="【Coref】【论文笔记】A Hybrid Approach to Multilingual Coreference Resolution">
  <span>
  【Coref】【论文笔记】A Hybrid Approach to Multilingual Coreference Resolution</span>
</a>
</div>


<div class="next">
<a href="/2017/08/24/coref-conll数据格式/" title="【Coref】conll2011数据格式">
 <span>【Coref】conll2011数据格式
</span>
</a>
</div>

</nav>

	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">
<div id="authorInfo">
	
		<div class="author-img"></div>		
	
	<div class="social-info">
		
		
		
		
		
		
		
		
		
		
		
		<a href="mailto:candnes@sina.com" target="_blank" class="icon-email" title="Email Me"></a>
		

	</div>
</div>

  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/NLP/" title="NLP">NLP<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/Coreference-Resolution/" title="Coreference Resolution">Coreference Resolution<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/NL2SQL/" title="NL2SQL">NL2SQL<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/学习/" title="学习">学习<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/踩坑/" title="踩坑">踩坑<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/爬虫/" title="爬虫">爬虫<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/多模态/" title="多模态">多模态<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/GNN/" title="GNN">GNN<sup>1</sup></a></li>
			
		
		</ul>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer">
		
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/hsihohuang/kiddochan" target="_blank" title="Kiddochan">Kiddochan</a> © 2023 
		
		<a href="/about" target="_blank" title="Yuanqing Zhu">Yuanqing Zhu</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>









<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
